[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "google.generativeai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "GoogleGenerativeAI",
        "importPath": "langchain_google_genai",
        "description": "langchain_google_genai",
        "isExtraImport": true,
        "detail": "langchain_google_genai",
        "documentation": {}
    },
    {
        "label": "GoogleGenerativeAI",
        "importPath": "langchain_google_genai",
        "description": "langchain_google_genai",
        "isExtraImport": true,
        "detail": "langchain_google_genai",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "fetch_all_files",
        "importPath": "github_search",
        "description": "github_search",
        "isExtraImport": true,
        "detail": "github_search",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "importPath": "analyze_code",
        "description": "analyze_code",
        "isExtraImport": true,
        "detail": "analyze_code",
        "documentation": {}
    },
    {
        "label": "analyzer_langChain",
        "importPath": "analyze_code",
        "description": "analyze_code",
        "isExtraImport": true,
        "detail": "analyze_code",
        "documentation": {}
    },
    {
        "label": "analyzer_streamed",
        "importPath": "analyze_code",
        "description": "analyze_code",
        "isExtraImport": true,
        "detail": "analyze_code",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "stringify",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "upload_to_gemini",
        "kind": 2,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "def upload_to_gemini(path, mime_type=None):\n  \"\"\"Uploads the given file to Gemini.\n  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n  \"\"\"\n  file = genai.upload_file(path, mime_type=mime_type)\n  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n  return file\n# https://ai.google.dev/api/python/google/generativeai/GenerativeModel\ngeneration_config = {\n  \"temperature\": 1,",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "format_response_as_markdown",
        "kind": 2,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "def format_response_as_markdown(response_dict):\n    \"\"\"Formats the response dictionary as markdown.\"\"\"\n    markdown_response = \"\"\n    for filename, details in response_dict.items():\n        markdown_response += f\"### {filename}\\n\"\n        markdown_response += f\"**Description:** {details['description']}\\n\\n\"\n        markdown_response += f\"**Tech Stack:** {', '.join(details['tech_stack'])}\\n\\n\"\n        markdown_response += f\"**Skillset:** {', '.join(details['skillset'])}\\n\\n\"\n    return markdown_response\ndef analyzer(model: genai.GenerativeModel=model, code_content='', question=\"\"):",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "analyzer",
        "kind": 2,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "def analyzer(model: genai.GenerativeModel=model, code_content='', question=\"\"):\n# TODO Make these files available on the local file system\n# You may need to update the file paths\n    response = model.generate_content(f\"Based on the code contents {code_content} answer this question {question}\")\n    # print(\"HERE IS THE RESPONSE*****************************\")\n    # print(response.text)\n    return response.text\nllm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GEMINI_KEY)\n# Analyzer function using langchain\ndef analyzer_langChain(code_content='', question=\"\"):",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "analyzer_langChain",
        "kind": 2,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "def analyzer_langChain(code_content='', question=\"\"):\n    system_instruction = f\"I am giving you content of all the files inside a repository. Your job is to analyze the code and technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format. and answer this {{question}}\"\n    template = f\"\"\"{system_instruction}\n    Based on the code contents {{code_content}} answer .\"\"\"\n    prompt = PromptTemplate.from_template(template)\n    chain = prompt | llm\n    response = chain.invoke({\"code_content\": code_content, \"question\": question})\n    return response\ndef analyzer_streamed(code_content='', question=''):\n    system_instruction = \"I am giving you content of all the files inside a repository. Your job is to analyze the code and tell technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format.\"",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "analyzer_streamed",
        "kind": 2,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "def analyzer_streamed(code_content='', question=''):\n    system_instruction = \"I am giving you content of all the files inside a repository. Your job is to analyze the code and tell technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format.\"\n    template = f\"\"\"{system_instruction}\n    Based on the code contents {{code_content}} answer this question {{question}}.\"\"\"\n    prompt = PromptTemplate.from_template(template)\n    chain = prompt | llm\n    # response = chain.invoke({\"code_content\": code_content, \"question\": question})\n    for chunk in chain.stream({\"code_content\": code_content, \"question\": question}):\n        yield chunk",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "GEMINI_KEY",
        "kind": 5,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "GEMINI_KEY = os.getenv('GEMINI_API_KEY')\ngenai.configure(api_key=GEMINI_KEY)\ndef upload_to_gemini(path, mime_type=None):\n  \"\"\"Uploads the given file to Gemini.\n  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n  \"\"\"\n  file = genai.upload_file(path, mime_type=mime_type)\n  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n  return file\n# https://ai.google.dev/api/python/google/generativeai/GenerativeModel",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "generation_config",
        "kind": 5,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "generation_config = {\n  \"temperature\": 1,\n  \"top_p\": 0.95,\n  \"top_k\": 64,\n  \"max_output_tokens\": 8192,\n}\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  generation_config=generation_config,\n  # safety_settings = Adjust safety settings",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "model = genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  generation_config=generation_config,\n  # safety_settings = Adjust safety settings\n  # See https://ai.google.dev/gemini-api/docs/safety-settings\n  system_instruction=\"I am giving you content of all the files inside a repository. Your job is to analyze the code and tell technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format\",\n)\ndef format_response_as_markdown(response_dict):\n    \"\"\"Formats the response dictionary as markdown.\"\"\"\n    markdown_response = \"\"",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "backend.analyze_code",
        "description": "backend.analyze_code",
        "peekOfCode": "llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GEMINI_KEY)\n# Analyzer function using langchain\ndef analyzer_langChain(code_content='', question=\"\"):\n    system_instruction = f\"I am giving you content of all the files inside a repository. Your job is to analyze the code and technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format. and answer this {{question}}\"\n    template = f\"\"\"{system_instruction}\n    Based on the code contents {{code_content}} answer .\"\"\"\n    prompt = PromptTemplate.from_template(template)\n    chain = prompt | llm\n    response = chain.invoke({\"code_content\": code_content, \"question\": question})\n    return response",
        "detail": "backend.analyze_code",
        "documentation": {}
    },
    {
        "label": "search_code",
        "kind": 2,
        "importPath": "backend.api_service",
        "description": "backend.api_service",
        "peekOfCode": "def search_code():\n    \"\"\"\n    API endpoint to retrieve file content github\n    Request JSON Body:\n    - username (str): username for github\n    - repo (str): repo name for github\n    Returns:\n    - JSON: A response containing a list of code contents or an error message.\n    \"\"\"\n    # TODO: Parse the request body and call merge_code_content",
        "detail": "backend.api_service",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.api_service",
        "description": "backend.api_service",
        "peekOfCode": "app = Flask(__name__)\n# EXPOSED API INTERFACE\nCORS(app)\n@app.route('/summarise', methods=['POST'])\ndef search_code():\n    \"\"\"\n    API endpoint to retrieve file content github\n    Request JSON Body:\n    - username (str): username for github\n    - repo (str): repo name for github",
        "detail": "backend.api_service",
        "documentation": {}
    },
    {
        "label": "get_repo_content",
        "kind": 2,
        "importPath": "backend.github_search",
        "description": "backend.github_search",
        "peekOfCode": "def get_repo_content(owner: str, repo: str, path: str = '') -> List[dict]:\n    \"\"\"\n    Fetch the contents of a GitHub repository.\n    Parameters:\n    - owner (str): GitHub username\n    - repo (str): Repository name\n    - path (str): Path within the repository (default is root)\n    Returns:\n    - List[dict]: List of repository contents\n    \"\"\"",
        "detail": "backend.github_search",
        "documentation": {}
    },
    {
        "label": "get_file_content",
        "kind": 2,
        "importPath": "backend.github_search",
        "description": "backend.github_search",
        "peekOfCode": "def get_file_content(owner: str, repo: str, path: str) -> str:\n    \"\"\"\n    Fetch the content of a file in a GitHub repository.\n    Parameters:\n    - owner (str): GitHub username\n    - repo (str): Repository name\n    - path (str): Path to the file within the repository\n    Returns:\n    - str: Decoded content of the file\n    \"\"\"",
        "detail": "backend.github_search",
        "documentation": {}
    },
    {
        "label": "fetch_all_files",
        "kind": 2,
        "importPath": "backend.github_search",
        "description": "backend.github_search",
        "peekOfCode": "def fetch_all_files(owner: str, repo: str, path: str = '') -> List[Tuple[str, str]]:\n    \"\"\"\n    Recursively fetch the content of all code files in a GitHub repository.\n    Parameters:\n    - owner (str): GitHub username\n    - repo (str): Repository name\n    - path (str): Path within the repository (default is root)\n    Returns:\n    - List[Tuple[str, str]]: List of tuples containing file paths and their content\n    \"\"\"",
        "detail": "backend.github_search",
        "documentation": {}
    },
    {
        "label": "GITHUB_TOKEN",
        "kind": 5,
        "importPath": "backend.github_search",
        "description": "backend.github_search",
        "peekOfCode": "GITHUB_TOKEN = os.getenv('GITHUBTOKEN')\n# Set headers for authorization\nheaders = {\n    'Authorization': f'token {GITHUB_TOKEN}'\n}\ndef get_repo_content(owner: str, repo: str, path: str = '') -> List[dict]:\n    \"\"\"\n    Fetch the contents of a GitHub repository.\n    Parameters:\n    - owner (str): GitHub username",
        "detail": "backend.github_search",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "backend.github_search",
        "description": "backend.github_search",
        "peekOfCode": "headers = {\n    'Authorization': f'token {GITHUB_TOKEN}'\n}\ndef get_repo_content(owner: str, repo: str, path: str = '') -> List[dict]:\n    \"\"\"\n    Fetch the contents of a GitHub repository.\n    Parameters:\n    - owner (str): GitHub username\n    - repo (str): Repository name\n    - path (str): Path within the repository (default is root)",
        "detail": "backend.github_search",
        "documentation": {}
    },
    {
        "label": "analyzer_langChain",
        "kind": 2,
        "importPath": "backend.llm_playground",
        "description": "backend.llm_playground",
        "peekOfCode": "def analyzer_langChain(code_content='', question=\"\"):\n    system_instruction = \"I am giving you content of all the files inside a repository. Your job is to analyze the code and tell technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format.\"\n    template = f\"\"\"{system_instruction}\n    Based on the code contents {{code_content}} answer this question {{question}}.\"\"\"\n    prompt = PromptTemplate.from_template(template)\n    chain = prompt | llm\n    # response = chain.invoke({\"code_content\": code_content, \"question\": question})\n    for chunk in chain.stream({\"code_content\": code_content, \"question\": question}):\n        yield chunk\nprint(analyzer_langChain())",
        "detail": "backend.llm_playground",
        "documentation": {}
    },
    {
        "label": "GEMINI_KEY",
        "kind": 5,
        "importPath": "backend.llm_playground",
        "description": "backend.llm_playground",
        "peekOfCode": "GEMINI_KEY = os.getenv('GEMINI_API_KEY')\nllm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GEMINI_KEY)\n# Analyzer function using langchain\ndef analyzer_langChain(code_content='', question=\"\"):\n    system_instruction = \"I am giving you content of all the files inside a repository. Your job is to analyze the code and tell technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format.\"\n    template = f\"\"\"{system_instruction}\n    Based on the code contents {{code_content}} answer this question {{question}}.\"\"\"\n    prompt = PromptTemplate.from_template(template)\n    chain = prompt | llm\n    # response = chain.invoke({\"code_content\": code_content, \"question\": question})",
        "detail": "backend.llm_playground",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "backend.llm_playground",
        "description": "backend.llm_playground",
        "peekOfCode": "llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GEMINI_KEY)\n# Analyzer function using langchain\ndef analyzer_langChain(code_content='', question=\"\"):\n    system_instruction = \"I am giving you content of all the files inside a repository. Your job is to analyze the code and tell technically the description of what each file is doing and the tech stack and skillset needed to work on this project. Return as a markdown in human readable format.\"\n    template = f\"\"\"{system_instruction}\n    Based on the code contents {{code_content}} answer this question {{question}}.\"\"\"\n    prompt = PromptTemplate.from_template(template)\n    chain = prompt | llm\n    # response = chain.invoke({\"code_content\": code_content, \"question\": question})\n    for chunk in chain.stream({\"code_content\": code_content, \"question\": question}):",
        "detail": "backend.llm_playground",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "def stringify(value):\n    return _stringify(value, separators=(',', ':'))\nassert stringify([None, None]) == '[[null,null]]'\na = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "a = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['o']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "b = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['one']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['two']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['three']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['a']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['test']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['array']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a2",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "a2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o2",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "str",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "str = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "oo",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "oo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "upload_to_gemini",
        "kind": 2,
        "importPath": "tempCodeRunnerFile",
        "description": "tempCodeRunnerFile",
        "peekOfCode": "def upload_to_gemini(path, mime_type=None):\n#   \"\"\"Uploads the given file to Gemini.\n#   See https://ai.google.dev/gemini-api/docs/prompting_with_media\n#   \"\"\"\n#   file = genai.upload_file(path, mime_type=mime_type)\n#   print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n#   return file\n# # Create the model\n# # See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n# generation_config = {",
        "detail": "tempCodeRunnerFile",
        "documentation": {}
    }
]